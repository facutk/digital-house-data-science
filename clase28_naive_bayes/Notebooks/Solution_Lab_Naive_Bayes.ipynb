{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB: Naive Bayes\n",
    "\n",
    "El objetivo de este lab es armar una clasificador que puede diferenciar comentarios negativos y positivos de películas (extraidos de [IMDB](http://www.imdb.com/) con la mayor efectividad posible. Observen cómo el dataset tiene (en principio) dos campos:\n",
    "\n",
    "    + sentence: que contiene el texto del comentario acerca de la película\n",
    "    + sentiment: la clasificación del comentario como positivo ($sentiment=1$) o negativo($sentiment=0)\n",
    "\n",
    "#### Importamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuente: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./../Data/imdb_labelled.txt', names=[\"sentence\", 'sentiment'], sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorización de los features\n",
    "\n",
    "Al igual que lo que hicimos en la práctica guiada, vamos a implementar un enfoque usado en análisis de texto, conocido como \"bag of words\". La idea es que se pueden extrear features (predictores) de un cuerpo de texto basado en las palabras que lo conforman. Pero es necesario transformar y procesar las palabras en el texto para poder hacerlas inteligibles para un clasificador.\n",
    "\n",
    "El enfoque que utilizamos en la práctica guiada fue calcular el tf-idf para que las palabras muy frecuentes en todo el corpus redujeran su importancia.\n",
    "\n",
    "Otra posibilidad para deshacernos de términos que no aportan información es utilizar lo que se conoce como \"stop words\". Las \"stop words\" son listados de palabras que se construyen manualmente con los términos más frecuentes de cada idioma que no contienen información específica sobre la temática de la cual habla el texto.\n",
    "Scikit learn tiene un listado de stopwords en inglés. Si queremos clasificar texto en español o en otros idiomas, existen paquetes de python que nos pueden ayudar a construir la lista de stopwords, como por ejemplo: https://pypi.python.org/pypi/stop-words\n",
    "\n",
    "\n",
    "A diferencia de lo que hicimos en la práctica guiada, para realizar la vectorización vamos a usar un método de `sklearn` llamado [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) \n",
    "\n",
    "**Hint:** pueden revisar [este ejemplo de uso y análisis de texto](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) en `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separación entre train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sentence'], df['sentiment'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "modelo_cvec = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = modelo_cvec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementación, predicción y evaluación del modelo\n",
    "\n",
    "A continuación, les pedimos que implementen un clasificador de tipo Naive Bayes, que evalúen su performance sobre datos no observados y que construyan una matriz de confusión para evaluar específicamente en qué clase el modelo comete mayor cantidad de errores de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "modelo_NB = MultinomialNB()\n",
    "modelo_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicción\n",
    "X_test = modelo_cvec.transform(X_test)\n",
    "labels_predichas = modelo_NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero calculamos el accuracy general del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, labels_predichas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora calculamos la matriz de confusión\n",
    "mat = confusion_matrix(y_test, labels_predichas)\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['negativo','positivo'], yticklabels=['negativo','positivo'])\n",
    "plt.xlabel('Etiquetas verdaderas')\n",
    "plt.ylabel('Etiquetas predichas');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
