{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB: Pipelines y Transformadores\n",
    "\n",
    "\n",
    "## 1. Introducción\n",
    "En este Lab vamos a crear Pipelines para pre-procesar datos y extraer características sobre el [Titanic dataset](http://www.kaggle.com/c/titanic-gettingStarted/data).\n",
    "\n",
    "El dataset es una lista de pasajeros del trasatlántico más famoso. La segunda columna del dataset (\"survived\") indica si la persona ha sobrevivido (1) o no (0) al naufragio. El resto de las columnas contienen información diversa sobre cada uno de los pasajeros.\n",
    "\n",
    "* Levantamos el dataset (Titanic.csv) en un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('Titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer una primera exploración de los datos:\n",
    "\n",
    "- ¿Hay features numéricas?\n",
    "- ¿Hay features categóricas?\n",
    "- ¿Hay datos incompletos? ¿En qué columnas?\n",
    "- ¿Cuáles te parecen importantes para rellenar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesando cada grupo de columnas\n",
    "\n",
    "Observamos que el preprocesamiento de los datos requiere distintos enfoques para distintos tipos de columnas: algunas requieren imputación, otras requieren generar variables Dummies y otras sería conveniente estandarizarlas.\n",
    "\n",
    "La idea es armar un pipeline separado para el preprocesamiento que necesita cada grupo de variables y luego unirlos todos con el método make_union() que ejecutará todos los pipelines para luego concatenar el resultado.\n",
    "\n",
    "Para hacer las transformaciones de cada grupo de columnas sugerimos crear un transformer de sklearn ColumnSelector que permita seleccionar un grupo de columnas del DataFrame donde queremos aplicar las transformaciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Edad\n",
    "\n",
    "Se puede observar que hay varios pasajeros sin información de edad (columna \"Age\"). Vamos a intentar llenar los datos de esta columna. Exploremos la distribución de valores para los datos existentes y pensemos una estrategia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.plot(kind = 'hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformador de Edad\n",
    "\n",
    "Dependiendo la estrategia que hayamos decido vamos a necesitar imputar los datos de edad faltantes, ya sea usando un transformador del módulo de pre-procesamiento o crear un transformador custom transformer.\n",
    "Esto podría implicar:\n",
    "\n",
    "- Llenar los datos faltantes\n",
    "- Escalar los valores de Edad\n",
    "\n",
    "¿Qué clases de sklearn permiten imputar datos y llenar valores faltantes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return pd.DataFrame(X[self.columns])\n",
    "        else:\n",
    "            raise TypeError(\"Este Transformador solo funciona en DF de Pandas\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ColumnSelector('Age')\n",
    "cs.transform(df).sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_pipe = make_pipeline(ColumnSelector('Age'),\n",
    "                         Imputer(),\n",
    "                         StandardScaler()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Variables Categóricas\n",
    "\n",
    "\"Embarked\" y \"Pclass\" son variables categóricas. Usá la función get_dummies de pandas para crear columnas correspondientes a los valores de las mismas.\n",
    "\n",
    "\"Embarked\" tiene un par de datos faltantes. Llenalos con el puerto de embarque más común en el dataset.\n",
    "\n",
    "Sugerencia: Crear un transformador custom que \"envuelva\" el uso de get_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.Embarked = df.Embarked.fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(pd.DataFrame(df['Embarked'].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDummiesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return pd.get_dummies(X[self.columns], columns = self.columns, drop_first = True)\n",
    "        else:\n",
    "            raise TypeError(\"Este Transformador solo funciona en DF de Pandas\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdt = GetDummiesTransformer(['Embarked'])\n",
    "gdt.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_pipe = GetDummiesTransformer(['Pclass', 'Embarked', 'Sex'])\n",
    "\n",
    "dummies_pipe.fit_transform(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3  Estandarizar la Tarifa\n",
    "\n",
    "Escalar el atributo \"Fare\" (Tarifa) usando uno de los escaladores existentes en el módulo de preprocesamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_pipe = make_pipeline(ColumnSelector('Fare'),\n",
    "                          StandardScaler())\n",
    "\n",
    "fare_pipe.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Union\n",
    "\n",
    "Utilizá una FeatureUnion o la función make_union para combinar todos los pipelines que has creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = make_union(age_pipe,\n",
    "                   dummies_pipe,\n",
    "                   fare_pipe)\n",
    "\n",
    "union.fit_transform(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = df['Survived']\n",
    "\n",
    "X = union.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicciones\n",
    "\n",
    "Ahora utilicemos GridSearch para evaluar la performance de estas transformaciones, seguidas de un modelo SVM. \n",
    "Para esto exploren distintos valores de parámetros para C y Gamma.\n",
    "\n",
    "Hagan un split entre train y test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "   ('union', union), \n",
    "   ('svc', SVC()), \n",
    "])\n",
    "parameters = {\n",
    "    'svc__C': np.linspace(1e-2,1.5, 5),\n",
    "    'svc__gamma': ['auto',1e-3,1,1.1,1.2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[columns], df['Survived'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV (pipeline, parameters, n_jobs = -1 , verbose = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_) \n",
    "\n",
    "print(\"Best parameters set:\" )\n",
    "\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted (parameters . keys()):\n",
    "    print(\"\\t %s: %r\" % (param_name, best_parameters[param_name])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance sobre datos nuevos\n",
    "\n",
    "Con el mejor modelo seleccionado mediante cross validation en los datos de entrenamiento, evalúen el accuracy y el classification report sobre datos no observados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
