{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁCTICA GUIADA: Test Training Workflow\n",
    "\n",
    "## Introducción\n",
    "\n",
    "El objetivo de esta práctica es recorrer y profundizar las diferentes partes de la etapa de \"Modelado\" en el flujo de trabajo de Data Science. En efecto, supongamos que ya hemos concluido la etapa de limpieza y preprocesamiento de los datos. El paso siguiente es comenzar la etapa de análisis y modelado de la información. Hay tres grandes tareas que serán habitualmente realizadas en esta etapa (no excluyentes entre sí, de hecho será habitual encarar las tres en simultáneo):\n",
    "\n",
    "* Realizar el proceso de tunning de los hiperparámetros\n",
    "* Evaluar la performance de un modelo\n",
    "* Evaluar la performance de varios modelos\n",
    "\n",
    "A continuación presentamos un esquema estilizado del proceso:\n",
    "\n",
    "#### Un esquema posible del proceso de estimación y modelado\n",
    "_______________________________________________________________________________________________________________\n",
    "\n",
    "1. Realizar una separación entre Train y Test Sets.\n",
    "\n",
    "2. Sobre el **set de entrenamiento (Train Set):** \n",
    "    \n",
    "    1. *Selección de los modelos a evaluar:* por ahora estamos trabajando sobre el de regresión modelo lineal y sus extensiones.\n",
    "    \n",
    "    2. *Proceso de Tunning de los Hiperparámetros:* hasta ahora hemos visto como primer hiperparámetro el $\\alpha$ para los modelos de regresión regularizados. Este proceso se realiza generalmente a partir de una estrategia de cross-validation.\n",
    "    \n",
    "    3. *Entrenamiento del modelo final:* Luego del proceso de selección y tunning de los hiperparámetros, es necesario realizar el entrenamiento final del modelo. Para ello, estimamos un modelo sobre el total del Training Set.\n",
    "    \n",
    "3. Sobre el **set de testing (Test Set):**\n",
    "       \n",
    "    1. Validación final del modelo (cálculo de errores y scores).\n",
    "      \n",
    "________\n",
    "\n",
    "En este LAB trabajaremos sobre estas diferentes etapas a partir de un dataset que busca modelar la progresión de la enfermedad diabetes. En efecto, el dataset contiene 10 variables fisiológicas (edad. sexo, índice de masa corporal y seis mediciones del plasma sanguíneo) medidas en 442 pacientes y un indicador de la progresión de la enfermedad luego de un año base.\n",
    "\n",
    "La idea será hacer predicciones sobre este indicador de progresión de la enfermedad, identificando los mejores modelos y los mejores predictores.\n",
    "\n",
    "El dataset está extraido de [un paper de Hastie y Tibshiriani](https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
    "\n",
    "Para ello, recorreremos los diferentes pasos de esta etapa.\n",
    "\n",
    "* En primer lugar, como siempre, importamos los diferentes paquetes a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Luego, cargamos el dataset y definimos los nombres de colmnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>map</th>\n",
       "      <th>tc</th>\n",
       "      <th>ldl</th>\n",
       "      <th>hdl</th>\n",
       "      <th>tch</th>\n",
       "      <th>ltg</th>\n",
       "      <th>glu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi       map        tc       ldl       hdl  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "        tch       ltg       glu  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = \"age sex bmi map tc ldl hdl tch ltg glu\".split()\n",
    "diabetes = datasets.load_diabetes()\n",
    "df = pd.DataFrame(diabetes.data, columns=columns)\n",
    "y = diabetes.target  # progresion de la enfermedad\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pareciera que las variables ya están normalizadas: \n",
    "    + $\\bar{x_{j}} \\approx 0$\n",
    "    \n",
    "    + $s_{j}=0.047619$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-3.634285e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>1.308343e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>-8.045349e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map</th>\n",
       "      <td>1.281655e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tc</th>\n",
       "      <td>-8.835316e-17</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ldl</th>\n",
       "      <td>1.327024e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdl</th>\n",
       "      <td>-4.574646e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tch</th>\n",
       "      <td>3.777301e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltg</th>\n",
       "      <td>-3.830854e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glu</th>\n",
       "      <td>-3.412882e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean       std\n",
       "age -3.634285e-16  0.047619\n",
       "sex  1.308343e-16  0.047619\n",
       "bmi -8.045349e-16  0.047619\n",
       "map  1.281655e-16  0.047619\n",
       "tc  -8.835316e-17  0.047619\n",
       "ldl  1.327024e-16  0.047619\n",
       "hdl -4.574646e-16  0.047619\n",
       "tch  3.777301e-16  0.047619\n",
       "ltg -3.830854e-16  0.047619\n",
       "glu -3.412882e-16  0.047619"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(['mean','std']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Previamente, estandarizamos las variables y features polinómicos de grado 2 con sus interacciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = np.array(df)\n",
    "X = StandardScaler().fit_transform(df)\n",
    "X = PolynomialFeatures(2,include_bias=True,interaction_only=False).fit_transform(df)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Paso 1. Hacer la separación entre Train Set y Test Set\n",
    "\n",
    "Scikit-learn tiene una función que se encarga de la separación entre test y entrenamiento llamada `train_test_split`. El parámetro `test_size` indica la propoción de los datos que vamos a separar para hacer la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 66) (309,)\n",
      "(133, 66) (133,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOBRE EL TRAIN SET\n",
    "### Paso 2A. Seleccionar los modelos a evaluar\n",
    "\n",
    "En este ejercicio probaremos tres modelos diferentes:\n",
    "    \n",
    "* regresión lineal (`LinearRegression()`)\n",
    "* regresión lineal regularizada Ridge (`Ridge()`, `RidgeCV()`)\n",
    "* regresión lineal regularizada LASSO (`Lasso()`, `LassoCV()`)\n",
    "\n",
    "Instanciemos, entonces, los modelos.\n",
    "\n",
    "Ahora bien, vamos a realizar el proceso de tunning de los hiperparámetros de los modelos en base a validación cruzada. Por eso, instanciamos previamente tres objetos:\n",
    "\n",
    "* un grid de diferentes valores $\\alpha$ para realizar el tunning de Ridge (`al_ridge`)\n",
    "* un grid de diferentes valores $\\alpha$ para realizar el tunning de Lasso (`al_lasso`)\n",
    "* un objeto que genera la partición del dataset en K partes para luego usar en el proceso de validación cruzada (`kf`). Al ejecutar `kf` el mismo provee los índices realizar el split del dataset. Notar que solamente instanciamos el `kf`. Luego, lo utilizaremos en la estimación de los hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generamos un grid de $\\alpha$ para probar e instanciamos un particionador del Training Set \n",
    "# en K partes para realizar la validación cruzada\n",
    "\n",
    "al_ridge = np.linspace(0.001, 0.3, 300)\n",
    "al_lasso = np.linspace(0.1, 0.5, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=12)\n",
    "\n",
    "# Instanciamos los modelos\n",
    "\n",
    "lm = LinearRegression()\n",
    "lmRidgeCV = RidgeCV(alphas=al_ridge, cv=kf, normalize=False)\n",
    "lmLassoCV = LassoCV(alphas=al_lasso, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Luego, hacemos el fit de los tres estimadores, lo cual nos lleva a...\n",
    "\n",
    "### Paso 2B. Proceso de Tunning de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([ 0.1    ,  0.10134, ...,  0.49866,  0.5    ]),\n",
       "    copy_X=True, cv=KFold(n_splits=5, random_state=12, shuffle=True),\n",
       "    eps=0.001, fit_intercept=True, max_iter=1000, n_alphas=100, n_jobs=1,\n",
       "    normalize=False, positive=False, precompute='auto', random_state=None,\n",
       "    selection='cyclic', tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos los fits respectivos\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "lmRidgeCV.fit(X_train, y_train)\n",
    "lmLassoCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante tener en claro que sucedió al ejecutar esta celda.\n",
    "\n",
    "1. Hicimos un fit de un modelo de regresión lineal en el Training Set.\n",
    "2. Usando `lmRidgeCV`, realizamos el proceso de tunning del $\\alpha$ en el modelo regularizado vía Ridge; a su vez, usamos el particionador `kf` con el que definimos que haríamos una Cross-Validation de K=5, haciendo un shuffle del dataset previamente.\n",
    "3. Usando `lmRidgeCV`, realizamos el tunning del $\\alpha$ para el modelo LASSO (usando el mismo particionador `kf`)\n",
    "\n",
    "Veamos cuáles son los $\\alpha$ estimados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Ridge: 0.004 \n",
      "Alpha LASSO: 0.1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Alpha Ridge:',lmRidgeCV.alpha_,'\\n'\n",
    "      'Alpha LASSO:',lmLassoCV.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2C. Estimación del modelo final sobre todo el Training Set\n",
    "\n",
    "Ya estamos en condiciones de realizar la estimación final de los modelos sobre los datos de Training Set, para luego realizar la validación final y seleccionar el modelo a utilizar.\n",
    "\n",
    "El modelo de regresión lineal (al no tener hiperparámetros) ya está listo. Lo que nos queda es seleccionar los hiperparámetros $\\alpha_{ridge}$ y $\\alpha_{lasso}$ que minimicen los errores cross-validados respectivos. En este punto, podríamos ejecutar el siguiente código para el caso del modelo Ridge:\n",
    "\n",
    "``` python\n",
    "\n",
    "a = lmRidgeCV.alpha_\n",
    "ridgefinal = Ridge(a)\n",
    "ridgefinal.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "* Buscamos el $\\alpha_{ridge}$ óptimo dentro del objeto `RidgeCV`.\n",
    "* Instanciamos el estimador `Ridge`.\n",
    "* Hacemos el fit. \n",
    "\n",
    "Con esto, tendríamos estimado el modelo, es decir... todos los parámetros (en este caso, $\\beta_{i}$ regularizados. Luego, repetiríamos el mismo proceoso para Lasso\n",
    "\n",
    "Afortunadamente, Scikit-Learn tiene implementado este procedimiento dentro de los mismos estimadores `RidgeCV` y `LassoCV`. De esta forma, ya se hizo el \"fit\" con el $\\alpha$ mínimo en cada caso. Por esto, podemos llamar directamente al método `.predict` dentro de cada uno de los modelos.\n",
    "\n",
    "En este [link](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) y en [este](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) pueden consultar más en profundidad sobre los estiamdores en cuestión...\n",
    "\n",
    "**NOTA:** Más adelante en el curso, veremos cómo \"encapsular\" estos procesos en un proceso más general que se llama [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), particularmente útil cuando tenemos muchos modelos a evaluar, con muchos hiperparámetros a tunear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Solamente por curiosidad, veamos qué performance tiene cada modelo en el Training Set.\n",
    "* Calculemos el $R^2$ y el MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Train Lineal: 0.621339560541 \n",
      "Score Train Ridge: 0.548021177506 \n",
      "Score Train Lasso: 0.499212866867\n",
      "Train MSE lineal= 2155.23494961 \n",
      "Train MSE Ridge= 2572.54377066 \n",
      "Train MSE Lasso= 2850.34775005\n"
     ]
    }
   ],
   "source": [
    "# Calculamos el R2\n",
    "\n",
    "print(\"Score Train Lineal:\", lm.score(X_train, y_train),\"\\n\"\n",
    "      \"Score Train Ridge:\",  lmRidgeCV.score(X_train, y_train),\"\\n\"\n",
    "      \"Score Train Lasso:\",  lmLassoCV.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el MSE\n",
    "\n",
    "lmpred_Tr = lm.predict(X_train)\n",
    "lmRidgepred_Tr = lmRidgeCV.predict(X_train)\n",
    "lmLassoepred_Tr = lmLassoCV.predict(X_train)\n",
    "\n",
    "print(\"Train MSE lineal=\", mean_squared_error(y_train,lmpred_Tr), \"\\n\"\n",
    "      \"Train MSE Ridge=\",  mean_squared_error(y_train,lmRidgepred_Tr), \"\\n\"\n",
    "      \"Train MSE Lasso=\",  mean_squared_error(y_train,lmLassoepred_Tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* ¿Cuáles son los parámetros de cada modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.79953958211587,\n",
       " array([  1.74244375e-08,   5.18889669e+01,  -2.77930919e+02,\n",
       "          3.29161064e+02,   4.08837910e+02,  -1.08791430e+04,\n",
       "          9.30457503e+03,   4.10294957e+03,   3.98191595e+02,\n",
       "          4.15989124e+03,   6.36068270e+01,   2.93433860e+03,\n",
       "          2.60191024e+03,  -2.15843519e+03,   7.48513056e+02,\n",
       "         -6.84998891e+03,  -2.91786145e+02,   7.40661489e+03,\n",
       "          5.53513354e+03,   4.59468910e+03,   1.08624636e+01,\n",
       "         -1.67828092e+00,   2.42996626e+03,   3.54302561e+03,\n",
       "          6.12788116e+03,  -5.08008608e+03,  -1.08375899e+03,\n",
       "         -1.35833122e+03,  -2.96844993e+03,   2.15522701e+02,\n",
       "          1.34378384e+03,   2.35979069e+03,  -1.85731500e+04,\n",
       "          1.88471882e+04,   2.90855480e+03,  -6.15499109e+03,\n",
       "          6.08487754e+03,   1.09589190e+03,   1.11728455e+02,\n",
       "          2.43792531e+04,  -1.33365112e+04,  -1.34970303e+04,\n",
       "         -8.62545053e+03,  -7.36697671e+03,  -4.09134938e+03,\n",
       "          4.71639470e+04,  -6.26115020e+04,  -3.20798724e+04,\n",
       "         -3.43189148e+04,  -2.40618835e+04,   6.28218054e+03,\n",
       "          2.61122341e+04,   1.99959480e+04,   1.62800569e+04,\n",
       "          9.98509218e+03,  -6.09321722e+03,   3.40382419e+03,\n",
       "          1.13812955e+04,   1.22336817e+04,   2.97608443e+03,\n",
       "          7.80149728e+03,   1.25960111e+04,   5.93770187e+03,\n",
       "          2.16216427e+04,  -2.14865653e+02,   1.50974838e+03]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lm.intercept_,lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144.24560945671513,\n",
       " array([   0.        ,   25.37551803, -240.58793224,  473.59840184,\n",
       "         356.98573419, -569.12984278,  341.23098749,  130.94940515,\n",
       "         287.8208953 ,  611.19149917,   27.37373493,  788.30506737,\n",
       "         951.32308735,  -73.28252273,  506.98767517,   15.02206887,\n",
       "        -192.05401658,   66.66432417,   17.36105681,  516.83045087,\n",
       "         257.76694398,   -1.45278595,  441.84637863,  662.01002896,\n",
       "         121.67982606,  -90.64170624,  364.67134895, -106.42023249,\n",
       "          12.28428891,  265.55742485,  590.4685136 ,  424.75897912,\n",
       "        -109.1358711 ,  -25.85014205,  -60.06010144,   87.10065885,\n",
       "         108.08628948,  430.00904008,   59.72522251,  301.09163978,\n",
       "         382.57822162,  -83.07833376,   88.92713352,  198.72533137,\n",
       "        -149.21851488,  276.64005202,  308.55290108,  390.95314095,\n",
       "        -401.70422127, -133.87921844,  410.75195998,  245.75637873,\n",
       "         142.03845794,   23.65881072,   29.1349514 ,  326.06804845,\n",
       "         -88.09642009,  -77.16196049,  452.46858688,  316.23166624,\n",
       "          35.43819293, -525.55353756,   74.36118874,  -23.54231444,\n",
       "         236.01611742,  616.66778853]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lmRidgeCV.intercept_,lmRidgeCV.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151.84474705120286,\n",
       " array([   0.        ,    0.        , -159.79396217,  490.65990843,\n",
       "         305.28197977,   -0.        ,   -0.        , -181.00887023,\n",
       "          21.98599896,  441.61710179,    4.29887889,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,   -0.        ,    0.        ,    0.        ,\n",
       "           0.        ,   -0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,   -0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "           0.        ,   -0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -0.        ,   -0.        ,    0.        ,    0.        ,\n",
       "           0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          -0.        ,   -0.        ,    0.        ,   -0.        ,\n",
       "           0.        ,   -0.        ,    0.        ,   -0.        ,\n",
       "           0.        ,    0.        ]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lmLassoCV.intercept_,lmLassoCV.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuáles son las variables más importantes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOBRE TEST SET\n",
    "### Paso 3. Hacer la validación final del modelo\n",
    "\n",
    "Lo único que queda es evaluar la performance del modelo. Para ello debemos usar datos que no hayan formado parte del proceso de entrenamiento anterior. Usaremos, entonces, el Test Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "lmpred_Te = lm.predict(X_test)\n",
    "lmRidgepred_Te = lmRidgeCV.predict(X_test)\n",
    "lmLassoepred_Te = lmLassoCV.predict(X_test)\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\"Test Score lineal=\", mean_squared_error(y_test,lmpred_Te), \"\\n\"\n",
    "      \"Test Score Ridge=\",  mean_squared_error(y_test,lmRidgepred_Te), \"\\n\"\n",
    "      \"Test Score Lasso=\",  mean_squared_error(y_test,lmLassoepred_Te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* ¿Con cuál se quedarían? ¿Cuál es el modelo que mejor performa? ¿Y el que peor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
