{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Guiada - Técnicas para datasets desbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de los datasets desbalanceados se encuentra en una amplia variedad de problemas de Machine Learning como la detección de comentarios hechos a través de bots, el diagnóstico de enfermedades o la búsqueda de transacciones fraudulentas en un sistema.\n",
    "\n",
    "Existen dos grandes enfoques para abordar datasets que se encuentran desbalanceados:\n",
    "\n",
    "1.  Hacer un resampling de la muestra, para entrenar al algoritmo con proporciones similares\n",
    "2.  Incorporar el desbalance a la función de costos del algoritmo para que tenga incentivos a elegir los parámetros que mejor discriminan la clase minoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación sobre datos desbalanceados\n",
    "\n",
    "A continuación presentamos un dataset de la empresa americana Lending Club, que se dedica a proveer servicios financieros para distintos segmentos. \n",
    "\n",
    "A continuación vamos a utilizar información abierta del portal de la empresa para intentar predecir cuáles de los créditos terminan en default. Para más información sobre el datset pueden ingresar <a href='https://www.lendingclub.com/info/download-data.action'> aquí </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv('loans.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio\n",
    "\n",
    "#### Balanceo de la clase\n",
    "\n",
    "La clase que vamos a intentar predecir es \"bad loans\" que indica si el préstamo fue pagado a tiempo o no. Observamos que la clase está desbalanceada, la mayoría de los préstamos se pagana tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['bad_loans'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables numéricas\n",
    "Podemos buscar las variables numéricas relevantes observando cuáles son las que tienen mayor correlación con la clase, bad_loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.corr()['bad_loans'].apply(abs).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables categóricas\n",
    "\n",
    "Para hacer el mismo análisis sobre variables categóricas, hacemos un group by por categoría para ver diferencias relevantes en la cantidad de créditos con default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.groupby('home_ownership')['bad_loans'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.groupby('term')['bad_loans'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.groupby('purpose')['bad_loans'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores faltantes\n",
    "\n",
    "Inspeccionamos los valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notamos que la variable payment_inc_ratio tiene sólo 4 valores nulos y mustra una correlación importante con la clase.\n",
    "# Además sabemos que la relación cuota/ingreso es importante a al hora de evaluar la capacidad de repago. \n",
    "# Eliminamos, entonces, los valores con payment_inc_ratio desconocido.\n",
    "loans = loans[loans.payment_inc_ratio.notnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Predictivo: regresión logística\n",
    "\n",
    "Vamos a utilizar Regresión Logística para predecir la clase bad_loans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generamos las variables dummies para los datos categóricos.\n",
    "loans_enconded = pd.get_dummies(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features, test_features, \\\n",
    "training_target, test_target, = train_test_split(loans_enconded.drop(['bad_loans'], axis=1),\n",
    "                                               loans_enconded['bad_loans'],\n",
    "                                               test_size = .1,\n",
    "                                               random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1e10)\n",
    "model.fit(training_features,training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_target,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_target,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando evaluamos el modelo sobre datos no observados, el área debajo de la curva es muy cercana a 0.5. Especificamente, el recall a la hora de encontrar los \"malos créditos\" es  muy malo. Uno de los problemas que tenemos para hacer un buen modelo es el desbalanceo de los datos. \n",
    "\n",
    "Vamos a intentar dos posibles soluciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aumentar la representación de la clase minoritaria vamos a hacer un oversampling utilizando el algoritmo SMOTE (Synthetic Minority Oversample) del paquete imblearn.\n",
    "\n",
    "Este algoritmo genera nuevos datos utilizando la técnica de los K vecinos más cercanos.\n",
    "Para generar un nuevo punto:\n",
    "\n",
    "1. Se elige un punto al azar de la clase minoritaria y sus K vecinos más cercanos.\n",
    "2. Se elige al azar uno de esos vecinos.\n",
    "3. Se calcula el vector entre el punto seleccionado y el vecino seleccionado al azar y se lo multiplica por un número aleatorio entre 0 y 1.\n",
    "4. El punto aleatorio dentro del vector es el nuevo dato para el oversampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=12)\n",
    "x_train_res, y_train_res = sm.fit_sample(training_features, training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_target,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_target,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Weights\n",
    "\n",
    "La otra técnica que podemos utilizar para corregir el desbalance de los datos es incorporar en la función de costos del algoritmo un mayor peso para los errores de entrenamiento cometidos sobre los puntos de la clase minoritaria.\n",
    "\n",
    "<strong> Ejercicio: Implementar la Regresión Logística con un parámetro que cambie la ponderación de las clases. <br />\n",
    "¿Cómo es la performance del nuevo modelo con respecto a la regresión logística original? <br />\n",
    "¿Tiene sentido aplicar esta corrección junto con el algoritmo SMOTE?\n",
    "<strong />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1e10, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_features,training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_target,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_target,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
